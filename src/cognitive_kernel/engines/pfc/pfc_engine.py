"""PFC (Prefrontal Cortex) Engine v1.0

ğŸ¬ ê¸°ì–µì˜ ì˜í™”ê´€ì—ì„œ "ì˜ì‚¬ê¸° + ê°ë…" ì—­í• 

í•µì‹¬ ê¸°ëŠ¥:
1. Working Memory: ì¤‘ìš” ì •ë³´ë¥¼ ì„ì‹œ ì €ì¥ (ìš©ëŸ‰ ì œí•œ, ì‹œê°„ ê°ì‡ )
2. Action Evaluator: í–‰ë™ì˜ ê¸°ëŒ€ íš¨ìš© ê³„ì‚° (U = reward - cost - risk*Îº)
3. Inhibitor: ìœ„í—˜í•œ í–‰ë™ ì–µì œ (Go/No-Go gate)
4. Selector: Softmax í™•ë¥ ì  í–‰ë™ ì„ íƒ
"""

from __future__ import annotations

import math
import time
import uuid
from typing import Dict, List, Optional, Tuple, Any

from .config import PFCConfig
from .models import WorkingMemorySlot, Action, ActionResult


class PFCEngine:
    """PFC Engine v1.0 - ì‘ì—… ê¸°ì–µ + í–‰ë™ ì„ íƒ + ì–µì œ ì—”ì§„."""

    def __init__(self, config: Optional[PFCConfig] = None):
        self.config = config or PFCConfig()
        self._working_memory: List[WorkingMemorySlot] = []
        self._current_goal: Optional[str] = None
        self._current_goal_priority: float = 0.5
        self._last_update_time: float = time.time()

    # ------------------------------------------------------------------
    # Working Memory
    # ------------------------------------------------------------------
    def load_to_working_memory(
        self,
        content: Any,
        relevance: float,
        source: str = "external",
    ) -> str:
        """ì‘ì—… ê¸°ì–µì— í•­ëª© ì¶”ê°€.

        ìš©ëŸ‰ ì´ˆê³¼ ì‹œ ê°€ì¥ ë‚®ì€ relevance í•­ëª© ì œê±° (Miller's Law).
        """
        slot_id = str(uuid.uuid4())
        slot = WorkingMemorySlot(
            id=slot_id,
            content=content,
            relevance=relevance,
            timestamp=time.time(),
            source=source,
        )

        self._working_memory.append(slot)

        # ìš©ëŸ‰ ì´ˆê³¼ ì‹œ eviction
        while len(self._working_memory) > self.config.working_memory_capacity:
            # ê°€ì¥ ë‚®ì€ relevance í•­ëª© ì œê±°
            min_idx = min(range(len(self._working_memory)),
                          key=lambda i: self._working_memory[i].relevance)
            self._working_memory.pop(min_idx)

        return slot_id

    def load_from_memoryrank(
        self,
        top_memories: List[Tuple[str, float]],
    ) -> List[str]:
        """MemoryRank ê²°ê³¼ë¥¼ ì‘ì—… ê¸°ì–µì— ë¡œë“œ.

        Args:
            top_memories: [(memory_id, rank_score), ...] from MemoryRank

        Returns:
            ìƒì„±ëœ ìŠ¬ë¡¯ ID ë¦¬ìŠ¤íŠ¸
        """
        slot_ids = []
        for memory_id, score in top_memories:
            # rank scoreë¥¼ relevanceë¡œ ë³€í™˜ (ì •ê·œí™”)
            relevance = min(1.0, score * 2.0)  # scoreëŠ” ë³´í†µ 0~0.5 ë²”ìœ„
            sid = self.load_to_working_memory(
                content={"memory_id": memory_id, "rank_score": score},
                relevance=relevance,
                source="memoryrank",
            )
            slot_ids.append(sid)
        return slot_ids

    def get_working_memory(self) -> List[WorkingMemorySlot]:
        """í˜„ì¬ ì‘ì—… ê¸°ì–µ ë‚´ìš© ë°˜í™˜."""
        return list(self._working_memory)

    def clear_working_memory(self) -> None:
        """ì‘ì—… ê¸°ì–µ ì´ˆê¸°í™”."""
        self._working_memory.clear()

    def update_decay(self, dt: Optional[float] = None) -> None:
        """ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ì‘ì—… ê¸°ì–µ ê°ì‡  ì ìš©.

        relevance(t) = relevance_0 Ã— exp(-Î» Ã— Î”t)
        """
        now = time.time()
        if dt is None:
            dt = now - self._last_update_time
        self._last_update_time = now

        decay_factor = math.exp(-self.config.decay_rate * dt)

        for slot in self._working_memory:
            # frozenì´ ì•„ë‹ˆë¯€ë¡œ ì§ì ‘ ìˆ˜ì •
            object.__setattr__(slot, 'relevance', slot.relevance * decay_factor)

        # relevanceê°€ ë„ˆë¬´ ë‚®ì€ í•­ëª© ì œê±° (0.01 ë¯¸ë§Œ)
        self._working_memory = [s for s in self._working_memory if s.relevance >= 0.01]

    # ------------------------------------------------------------------
    # Goal Management (v1.0: ë‹¨ì¼ ëª©í‘œë§Œ)
    # ------------------------------------------------------------------
    def set_goal(self, description: str, priority: float = 0.5) -> None:
        """í˜„ì¬ ëª©í‘œ ì„¤ì •."""
        self._current_goal = description
        self._current_goal_priority = max(0.0, min(1.0, priority))

    def get_goal(self) -> Optional[Tuple[str, float]]:
        """í˜„ì¬ ëª©í‘œ ë°˜í™˜."""
        if self._current_goal:
            return (self._current_goal, self._current_goal_priority)
        return None

    # ------------------------------------------------------------------
    # Action Evaluation
    # ------------------------------------------------------------------
    def evaluate_action(self, action: Action) -> float:
        """í–‰ë™ì˜ ê¸°ëŒ€ íš¨ìš©(Expected Utility) ê³„ì‚°.

        U(action) = expected_reward - effort_cost - risk Ã— risk_aversion
        """
        risk_penalty = action.risk * self.config.risk_aversion
        utility = action.expected_reward - action.effort_cost - risk_penalty
        return utility

    def evaluate_actions(self, actions: List[Action]) -> List[Tuple[Action, float]]:
        """ì—¬ëŸ¬ í–‰ë™ì˜ íš¨ìš© ê³„ì‚°."""
        return [(a, self.evaluate_action(a)) for a in actions]

    # ------------------------------------------------------------------
    # Inhibition
    # ------------------------------------------------------------------
    def calculate_conflict_signal(
        self,
        action: Action,
        competing_actions: Optional[List[Action]] = None,
    ) -> float:
        """ê°ˆë“± ì‹ í˜¸ ê³„ì‚°.

        conflict = max(competing_utilities) - current_utility (if > 0)
        ë˜ëŠ” riskê°€ ë†’ìœ¼ë©´ ê°ˆë“± ì‹ í˜¸ ì¦ê°€
        """
        current_utility = self.evaluate_action(action)

        # ìœ„í—˜ ê¸°ë°˜ ê°ˆë“±
        risk_conflict = action.risk

        # ê²½ìŸ í–‰ë™ ê¸°ë°˜ ê°ˆë“±
        competition_conflict = 0.0
        if competing_actions:
            competing_utilities = [self.evaluate_action(a) for a in competing_actions]
            max_competing = max(competing_utilities) if competing_utilities else 0.0
            if max_competing > current_utility:
                competition_conflict = max_competing - current_utility

        # ì¢…í•© ê°ˆë“± ì‹ í˜¸
        conflict_signal = max(risk_conflict, competition_conflict)
        return min(1.0, conflict_signal)

    def should_inhibit(
        self,
        action: Action,
        competing_actions: Optional[List[Action]] = None,
    ) -> Tuple[bool, float]:
        """ì–µì œ ì—¬ë¶€ íŒë‹¨ (Go/No-Go).

        Returns:
            (ì–µì œ ì—¬ë¶€, ê°ˆë“± ì‹ í˜¸)
        """
        conflict_signal = self.calculate_conflict_signal(action, competing_actions)
        inhibit = conflict_signal > self.config.inhibition_threshold
        return (inhibit, conflict_signal)

    # ------------------------------------------------------------------
    # Selection (Softmax)
    # ------------------------------------------------------------------
    def softmax_probabilities(self, utilities: List[float]) -> List[float]:
        """Softmax í™•ë¥  ê³„ì‚°.

        P(i) = exp(Î² Ã— U_i) / Î£ exp(Î² Ã— U_j)
        """
        beta = self.config.decision_temperature

        # overflow ë°©ì§€ë¥¼ ìœ„í•œ ì •ê·œí™”
        max_u = max(utilities) if utilities else 0.0
        exp_values = [math.exp(beta * (u - max_u)) for u in utilities]
        total = sum(exp_values)

        if total == 0:
            return [1.0 / len(utilities)] * len(utilities) if utilities else []

        return [e / total for e in exp_values]

    def select_action(
        self,
        actions: List[Action],
        deterministic: bool = False,
    ) -> ActionResult:
        """í–‰ë™ ì„ íƒ (Softmax ë˜ëŠ” argmax).

        Args:
            actions: í›„ë³´ í–‰ë™ ë¦¬ìŠ¤íŠ¸
            deterministic: Trueë©´ argmax, Falseë©´ softmax ìƒ˜í”Œë§

        Returns:
            ActionResult (ì„ íƒëœ í–‰ë™, íš¨ìš©, ì–µì œ ì—¬ë¶€ ë“±)
        """
        if not actions:
            return ActionResult(
                action=None,
                utility=0.0,
                inhibited=False,
                conflict_signal=0.0,
                selection_probability=0.0,
            )

        # íš¨ìš© ê³„ì‚°
        utilities = [self.evaluate_action(a) for a in actions]
        probabilities = self.softmax_probabilities(utilities)

        # ì„ íƒ
        if deterministic:
            max_idx = max(range(len(utilities)), key=lambda i: utilities[i])
        else:
            # í™•ë¥ ì  ìƒ˜í”Œë§
            import random
            r = random.random()
            cumsum = 0.0
            max_idx = len(actions) - 1
            for i, p in enumerate(probabilities):
                cumsum += p
                if r < cumsum:
                    max_idx = i
                    break

        selected_action = actions[max_idx]
        selected_utility = utilities[max_idx]
        selected_prob = probabilities[max_idx]

        # ì–µì œ ì²´í¬
        other_actions = [a for i, a in enumerate(actions) if i != max_idx]
        inhibit, conflict_signal = self.should_inhibit(selected_action, other_actions)

        if inhibit:
            return ActionResult(
                action=None,
                utility=selected_utility,
                inhibited=True,
                conflict_signal=conflict_signal,
                selection_probability=selected_prob,
            )

        return ActionResult(
            action=selected_action,
            utility=selected_utility,
            inhibited=False,
            conflict_signal=conflict_signal,
            selection_probability=selected_prob,
        )

    # ------------------------------------------------------------------
    # Integrated Pipeline
    # ------------------------------------------------------------------
    def process(
        self,
        candidate_actions: List[Action],
        top_memories: Optional[List[Tuple[str, float]]] = None,
        goal: Optional[str] = None,
        goal_priority: float = 0.5,
        deterministic: bool = False,
    ) -> ActionResult:
        """í†µí•© ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸.

        1. ëª©í‘œ ì„¤ì •
        2. MemoryRank ê²°ê³¼ ë¡œë“œ (ìˆìœ¼ë©´)
        3. ê°ì‡  ì ìš©
        4. í–‰ë™ ì„ íƒ

        Args:
            candidate_actions: í›„ë³´ í–‰ë™ ë¦¬ìŠ¤íŠ¸
            top_memories: MemoryRank ê²°ê³¼ (optional)
            goal: í˜„ì¬ ëª©í‘œ (optional)
            goal_priority: ëª©í‘œ ìš°ì„ ìˆœìœ„
            deterministic: argmax ì„ íƒ ì—¬ë¶€

        Returns:
            ActionResult
        """
        # 1. ëª©í‘œ ì„¤ì •
        if goal:
            self.set_goal(goal, goal_priority)

        # 2. MemoryRank ê²°ê³¼ ë¡œë“œ
        if top_memories:
            self.load_from_memoryrank(top_memories)

        # 3. ê°ì‡  ì ìš©
        self.update_decay()

        # 4. í–‰ë™ ì„ íƒ
        return self.select_action(candidate_actions, deterministic)

    # ------------------------------------------------------------------
    # Utility
    # ------------------------------------------------------------------
    def get_state(self) -> Dict:
        """í˜„ì¬ PFC ìƒíƒœ ë°˜í™˜."""
        return {
            "working_memory_count": len(self._working_memory),
            "working_memory_capacity": self.config.working_memory_capacity,
            "current_goal": self._current_goal,
            "goal_priority": self._current_goal_priority,
            "config": {
                "decay_rate": self.config.decay_rate,
                "risk_aversion": self.config.risk_aversion,
                "inhibition_threshold": self.config.inhibition_threshold,
                "decision_temperature": self.config.decision_temperature,
            },
        }
